{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Week5_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofzy8xHIXdQF",
        "colab_type": "text"
      },
      "source": [
        "[Bag of Words Meets Bags of Popcorn](https://www.kaggle.com/c/word2vec-nlp-tutorial/data)\n",
        "======\n",
        "\n",
        "## Data Set\n",
        "\n",
        "The labeled data set consists of 50,000 IMDB movie reviews, specially selected for sentiment analysis. The sentiment of reviews is binary, meaning the IMDB rating < 5 results in a sentiment score of 0, and rating >=7 have a sentiment score of 1. No individual movie has more than 30 reviews. The 25,000 review labeled training set does not include any of the same movies as the 25,000 review test set. In addition, there are another 50,000 IMDB reviews provided without any rating labels.\n",
        "\n",
        "## File descriptions\n",
        "\n",
        "labeledTrainData - The labeled training set. The file is tab-delimited and has a header row followed by 25,000 rows containing an id, sentiment, and text for each review.\n",
        "## Data fields\n",
        "\n",
        "* id - Unique ID of each review\n",
        "* sentiment - Sentiment of the review; 1 for positive reviews and 0 for negative reviews\n",
        "* review - Text of the review\n",
        "\n",
        "## Objective\n",
        "Objective of this dataset is base on **review** we predict **sentiment** (positive or negative) so X is **review** column and y is **sentiment** column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dub6uxUzXdQH",
        "colab_type": "text"
      },
      "source": [
        "## 1. Load Dataset\n",
        "\n",
        "Let's first of all have a look at the data. You can download the file `labeledTrainData.tsv` on the [Kaggle website of the competition](https://www.kaggle.com/c/word2vec-nlp-tutorial/data), or on our [Google Drive](https://drive.google.com/file/d/1a1Lyn7ihikk3klAX26fgO3YsGdWHWoK5/view?usp=sharing)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACS5v4oh80dC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e98d5b9d-286b-4eb7-a30b-0bd050269f16"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1WU9XkYXdQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pandas, numpy\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iH9rAw7XdQL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "0832316a-3c94-4804-f918-55e2fdb1dcc5"
      },
      "source": [
        "# Read dataset with extra params sep='\\t', encoding=\"latin-1\"\n",
        "data_train =  pd.read_csv(\"./gdrive/My Drive/devC_data/labeledTrainData.tsv\", sep='\\t', encoding='latin-1')\n",
        "data_train.sample()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>21975</th>\n",
              "      <td>4788_10</td>\n",
              "      <td>1</td>\n",
              "      <td>This is one of the greatest films I have ever ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            id  sentiment                                             review\n",
              "21975  4788_10          1  This is one of the greatest films I have ever ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0oArjGc-f_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "9036dbd4-b607-4fbf-8656-82ddb595e9ff"
      },
      "source": [
        "data_train.sample(5).review.values"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['\\\\Cypher\\\\\" is a cleverly conceived story about industrial espionage set in America in the not too distant future. While thematically not complex, this film does offer many different perspectives about personal loyalty, ruthlessness, and corporate conspiracy. To a certain extent this film also attempts to represent modern corporate groups and companies as being indifferent to the risks their contract employees take on their behalf.<br /><br />The film starts off with a somewhat mediocre salary man, Morgan Sullivan (Jeremy Northam), who applies to the Digicorp group to work as an undercover operative. After an initial briefing with Digicorp\\'s Security Chief, Sullivan is then given a new identity (Jack Thursby) and sent to a business conference with the task of recording the speeches given by various spokesmen concerning the marketing strategies of each of their respective companies. Upon successfully completing his first assignment, Sullivan/Thursby is sent on further missions to obtain the same type of information previously gathered. However, on one of his \\\\\"business trips\\\\\" he inadvertently runs into a woman named Rita Foster, (Liu) whom he had met on his previous assignment, and from there things go extremely topsy-turvy. The implications of a diabolical conspiracy involving Digicorp\\'s espionage program begin to emerge and Sullivan is forced to go deep cover at one of Digicorp\\'s main competitors, thus becoming a double agent involved in an intense rivalry between the two companies.<br /><br />((SPOILERS END HERE))<br /><br />What I liked most about this film was the efficient use of lighting and shadows in a lot of the scenes. Vivid lighting was used in mainly domestic/household settings, while a lot of shadows and dark coloring were used for settings involving deception and cover-up. I was also very impressed with Jeremy Northam. Not too often have I seen him in the lead role, and the fact that he plays a disenchanted married man straight out of Wisconsin was brilliant. Personally, I think he\\'s one of the many under used actors in the industry who hasn\\'t been given more challenging roles. Lucy Liu was also incredible in her part and gave the movie its real cloak-and-dagger tone. Additionally, the rest of the supporting cast did a superb job, however, my only complaint was that some characters could have been explored more to make the plot and closure a little more complicated. For example, I would have loved to see what would have happened if Jack Thursby had developed a more intimate relationship with his second \\\\\"wife.\\\\\" Overall, this is a cleverly developed cloak-and-dagger story that keeps you guessing to the very end about personal and professional loyalties and whether anyone in the entire film can be trusted. With a smart and stylish soundtrack and great camera work, this film provides a scary look at how corporations might operate in the near future. I\\'m surprised that I had never watched this \\\\\"hidden gem\\\\\" before. This is a brilliant, not-too-overly complicated spy thriller, and therefore I\\'m giving it a 9 out of 10.\"',\n",
              "       \"I had suspicions the movie was going to be bad. I'm a Duke's fan from way back. Have three years of the TV series on DVD. Well I was right. Took the family to see it. I really wanted to see the General jump again and some of the chase jump scenes were good. But to sum it up, the movie was a dumbed down tarted up version of the TV show.<br /><br />Jessica Simpson was pathetic. While I can honestly say that the original Daisy's outfits were just as revealing, Jessica Simpson's interpretation of Daisy was simply awful. Sorrel Booke and Denver Pyle must be rolling in their graves as well.<br /><br />Don't waste your money. If you are an old tried and true Dukes fan like me and my three kids are you will be very disappointed.\",\n",
              "       'This movie was bad beyond belief. I saw it during the 2004 San Francisco Film Festival. Before it started the owner of the theatre got up and told us how half the audience had left the theatre the night before, which happened to be its \\\\world premiere.\\\\\" I don\\'t think anyone in the theatre understood just how bad the movie was going to be at that point. We all understood by the end. <br /><br />Its not a documentary though it was sort of sold as one. Dark Angel was a bad biography and misguided homage to Bettie Paige, in which half the movie is actually just remakes of old Bettie Paige movies. The movie is only 90 minutes long and the content of those 90 minutes is sub par to say the least. A scene would start going then someone would say \\\\\"wow you\\'re so great Bettie, why don\\'t we make another movie.\\\\\" this would be followed by a 5 minutes of a Bettie Paige remake which was almost as ridiculous as (and even more boring than) the normal part of the movie. by the end of the movie people were laughing every time another Bettie Paige movie remake came up. it was that ludicrous. I heard a lot of laughter in that theatre, but people were not laughing with the movie maker, they were laughing at the movie and its poor content and structure. This was easy to tell as the parts that would get the most laughs were the ones which were supposed to be serious or revelatory. <br /><br />I know movies are expensive. I have seen many cheaply made independent films but somehow the cinematography and quality of this movie set it apart from anything else I have ever seen. The movie looks like it was made for $12. The cuts, the graininess, and the lack of a sensual plot made this a memorable experience. This movie makes \\\\\"Dude, Where\\'s My Car?\\\\\" look like Citizen Kane. <br /><br />My friends and I left the theatre feeling like we had just paid 8 dollars to be tortured. The only redeeming part of the experience was that we got to laugh about the fact that someone had actually made this movie and thought it was good. Apparently, the previous night, the night of the \\\\\"world premiere\\\\\" the director/writer/producer had been in the audience and had gotten to witness people laugh at and walk out on his movie. Bettie Paige\\'s movies were destroyed. They should destroy this movie too.\"',\n",
              "       \"This is an Arnold movie. Now that you know that, I've saved a lot of you the time it would have taken to read this review. If you don't like Arnold, then you wont like this movie. If the case is the other, then you will very probably like it. It's as simple as that.<br /><br />Now, if you're still reading this I expect you like Arnold. Good for you! He is quite good isn't he. The Running Man is a very typical Arnold feature. It's got the usual retro-future we know so well from 80's B-Sci Fi, it's got a bunch of terrible one-liners, lots of violence and explosions, and a good-looking heroine and a happy ending.<br /><br />In this case, the evil opponent is the all-controlling 1984ish government, which uses television as an effective crowd-control with gladiator-type game shows. Arnold, of course, ends up in one of these shows and turns it all up-side-down, with a little help from his two confederates and the good-looking Amber.<br /><br />It's not a big budget movie, but it still managed to create a pretty good atmosphere of the future, with some nice matte paintings and sets to help it. It's hopelessly 80's, but I find that charming. Acting is varying, Arnold doing his usual grunt and shout thing, with a helping of stone-faced one-liners. Heroine Amber is, to put it lightly, a bit stereotypical, and the subtly named Damen Killian is a typical evil TV man.<br /><br />In spite of all it's flaws, the movie shows its message very clearly; television is an opiate of the masses, a good way to control people. It also features some at the time futuristic digital video editing, allowing the bad guys to change faces in a video to fool their audience. This does not seem futuristic at all today, which is a bit alarming.<br /><br />If you've seen Arnold movies before then you know when to watch this one. Enjoy.\",\n",
              "       'When I saw it for the first time I was really impressed.The director made such a mysterious atmosphere, especially in the end. Through all the story spectators can expect that Richard will really kill Thomas or he will do it first.But..the main point was not conflict but..FRIENDSHIP!Older and mature one prayed himself to save the younger who has the whole life to life.It is amazing. Every time I watch it I enjoy!Of course it is pretty violent like every action movie but I think it is acceptable. Thanks a lot Louis Liosa and Tom Berenger! Amazing film!I advice everyone to see it.I am sure people wont regret and will really have a good time.'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv-Xu9_f_Cju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBoFh4L3-8AL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "dc9dc14c-b94d-493d-cfdf-d974b7aba495"
      },
      "source": [
        "raw_review = data_train.review.values[0]\n",
        "BeautifulSoup(raw_review, \"lxml\").get_text()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"With all this stuff going down at the moment with MJ i've started listening to his music, watching the odd documentary here and there, watched The Wiz and watched Moonwalker again. Maybe i just want to get a certain insight into this guy who i thought was really cool in the eighties just to maybe make up my mind whether he is guilty or innocent. Moonwalker is part biography, part feature film which i remember going to see at the cinema when it was originally released. Some of it has subtle messages about MJ's feeling towards the press and also the obvious message of drugs are bad m'kay.Visually impressive but of course this is all about Michael Jackson so unless you remotely like MJ in anyway then you are going to hate this and find it boring. Some may call MJ an egotist for consenting to the making of this movie BUT MJ and most of his fans would say that he made it for the fans which if true is really nice of him.The actual feature film bit when it finally starts is only on for 20 minutes or so excluding the Smooth Criminal sequence and Joe Pesci is convincing as a psychopathic all powerful drug lord. Why he wants MJ dead so bad is beyond me. Because MJ overheard his plans? Nah, Joe Pesci's character ranted that he wanted people to know it is he who is supplying drugs etc so i dunno, maybe he just hates MJ's music.Lots of cool things in this like MJ turning into a car and a robot and the whole Speed Demon sequence. Also, the director must have had the patience of a saint when it came to filming the kiddy Bad sequence as usually directors hate working with one kid let alone a whole bunch of them performing a complex dance scene.Bottom line, this movie is for people who like MJ on one level or another (which i think is most people). If not, then stay away. It does try and give off a wholesome message and ironically MJ's bestest buddy in this movie is a girl! Michael Jackson is truly one of the most talented people ever to grace this planet but is he guilty? Well, with all the attention i've gave this subject....hmmm well i don't know because people can be different behind closed doors, i know this for a fact. He is either an extremely nice but stupid guy or one of the most sickest liars. I hope he is not the latter.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbuaIdhWXdQO",
        "colab_type": "text"
      },
      "source": [
        "## 2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJr6juwHXdQP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0deeeef9-b107-491c-8b9b-28c833dcd4c8"
      },
      "source": [
        "# stop words\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v220Tp_XdQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Removing special characters and \"trash\"\n",
        "import re\n",
        "def preprocessor(text):\n",
        "    # Remove HTML markup\n",
        "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
        "\n",
        "    text = text.lower()\n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in stop_words]\n",
        "    text = \" \".join(text)\n",
        "    \n",
        "    return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i4TuNbVBb6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train['processed_reviews'] = data_train.review.apply(preprocessor)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjzOxu4MXdQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset in train and test\n",
        "# Your code here\n",
        "\n",
        "X = data_train[['processed_reviews']]\n",
        "y = data_train.sentiment.values\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Z_T9MFsC5Fs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1768f59b-248e-431b-d91c-3f690aeed359"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COr1xR7PXdQc",
        "colab_type": "text"
      },
      "source": [
        "## 3. Create Model and Train \n",
        "\n",
        "Using **Pipeline** to concat **tfidf** step and **LogisticRegression** step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IW-rllMD1AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "text_transformer = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=True, max_features=150000)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hS94u31FL8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5da39944-8413-4ee6-a250-af03e71e7245"
      },
      "source": [
        "%%time\n",
        "X_train_text = text_transformer.fit_transform(X_train['processed_reviews'])\n",
        "X_test_text = text_transformer.transform(X_test['processed_reviews'])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 14.1 s, sys: 345 ms, total: 14.5 s\n",
            "Wall time: 14.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOEwbQGfFizN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eaf4bec0-b582-4c0c-8728-26add4539f54"
      },
      "source": [
        "X_train_text"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<17500x150000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2166339 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOpwINJmXdQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "lg = LogisticRegression()\n",
        "lg.fit(X_train_text, y_train)\n",
        "predictions = lg.predict(X_test_text)\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYdoVMx_XdQf",
        "colab_type": "text"
      },
      "source": [
        "## 4. Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ZOzHoaXdQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "f812abd6-3b0e-4c59-ccb3-59c989685add"
      },
      "source": [
        "# Show metrics\n",
        "print(\"Accuracy score: %f\" % accuracy_score(y_test, predictions))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, predictions))\n",
        "print(classification_report(y_test, predictions))\n",
        "print('Log loss:', log_loss(y_test, predictions)/len(y_test))\n",
        "\n",
        "# Show parameters\n",
        "print('w = ', lg.coef_)\n",
        "print('b = ', lg.intercept_)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.884533\n",
            "Confusion Matrix:\n",
            "[[3250  488]\n",
            " [ 378 3384]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.88      3738\n",
            "           1       0.87      0.90      0.89      3762\n",
            "\n",
            "    accuracy                           0.88      7500\n",
            "   macro avg       0.88      0.88      0.88      7500\n",
            "weighted avg       0.88      0.88      0.88      7500\n",
            "\n",
            "Log loss: 0.000531750587760686\n",
            "w =  [[-0.08998597 -0.15358876  0.14132492 ... -0.03449163 -0.08202534\n",
            "  -0.1134814 ]]\n",
            "b =  [0.08870266]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}